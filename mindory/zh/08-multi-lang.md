# Mindory 的多语言支持：AI 阅读助手的工程化决策
Mindory 不只是一款阅读 App，更是一套** AI 辅助阅读系统** —— 核心目标是帮用户更高效地**理解和检索**书籍内容。

这个定位至关重要：当 AI 融入阅读流程（ 语义搜索、引文召回、上下文问答 ），**语言处理就从 “ UI 层面的展示问题”，升级为 “系统底层的核心问题”**。

本文将从工程视角，拆解 Mindory 在真实场景约束下，多语言支持的设计逻辑。


## 一、AI 辅助阅读重构了问题边界
传统阅读系统的核心需求是：
- 内容渲染
- 分页排版
- 字体与布局适配

而 AI 辅助阅读新增了更底层的要求：
- 文本的语义嵌入
- 书籍内容的向量检索
- 语言感知的提示词设计
- 多语言下语义质量的一致性

换句话说：
> 系统需要 “理解” 文本，而非仅 “展示” 文本。

一旦以 “理解” 为目标，多语言支持就不再是可选项 —— 而是系统的地基。


## 二、本地优先 AI 定义了硬性约束
Mindory 的定位是**本地优先的 AI 系统**，这意味着：
- 所有 embedding 在本地完成
- 不依赖云端 GPU
- 天生具备隐私保护性

从工程角度，我们的预设环境是：
- 仅用 CPU 运行
- 内存资源有限
- LLM 交互与书籍阅读并行

这直接收窄了技术选型的范围：
任何依赖 “大型多语言模型、高内存占用、长阻塞推理” 的方案，最终都会在真实用户环境中失效。


## 三、Embedding：小而专，可预测
### 为何不用大型多语言 Embedding 模型？
在云端场景下，大型多语言模型很有吸引力；但在本地 AI 阅读助手中，这类模型风险极高：
- CPU 推理速度慢
- 延迟不稳定
- 内存占用高
- 文本召回体验差

因此 Mindory 选择**轻量、语言专属的嵌入模型**。

### 当前选型
- `BAAI/bge-small-zh-v1.5` — 中文书籍
- `BAAI/bge-small-en-v1.5` — 英文书籍

这些模型的优势：
- 可在 CPU 上稳定运行
- 内存占用低
- 语义质量足以支撑：
  - 引文检索
  - 段落召回
  - 上下文问答

更大的模型可作为实验方向，但只有在本地环境中能证明 “资源成本与收益匹配” 时，才会落地。


## 四、纯 CPU Embedding 水线
没有 GPU 加速时，Embedding 就成了**工程调度问题**。

核心设计原则：
- Embedding 异步执行
- 阅读流程永不阻塞
- 文本按有限长度分片处理
- 索引增量式推进，而非全量重跑

这确保了：
- 阅读体验流畅
- 系统行为可预测
- 大篇幅书籍也能优雅处理

AI 辅助应是 “无感融入”，而非 “干扰阅读”。


## 五、向量库：跟随模型，而非预设
工程中常见的陷阱是 “硬编码 Embedding 模型维度”：
```text
embedding_dim = 384
```
这在模型不变时可行 —— 模型一旦更换，就会导致问题：
- 模型切换时的隐性不兼容
- 重新索引失败
- 调试难度高

### Mindory 的方案
- 嵌入维度从模型元数据中动态获取
- 向量库配置动态生成
- **每本书独立存储自己的向量库文件**

这套设计实现了：
- 模型升级安全
- 单本书独立重索引
- 故障隔离
- 未来多模态实验的可行性


## 六、 Prompt：多语言基建的一部分
在 AI 阅读助手中，提示词不是静态文本 —— 而是系统的一个插件。

工程考量：
- 根据书籍语言自动选择提示词
- 中文与英文提示词独立维护
- 提示词的语气、结构、指令与语言适配

这一设计的价值：
- 避免语义偏差
- 提升回答相关性
- 减少语言不匹配导致的幻觉

提示词被视为**版本化的系统资产**，而非内联字符串。


## 七、明确的工程取舍
Mindory 的多语言支持，建立在一系列主动取舍之上：

| 决策                     | 核心逻辑                     |
| ------------------------ | ---------------------------- |
| 轻量语言专属模型         | 保障 CPU 环境下的稳定性能      |
| 单本书独立向量库         | 隔离风险，安全重索引         |
| 动态嵌入维度             | 提升模型灵活性               |
| 语言适配提示词           | 保证语义质量                 |
| 纯本地处理             | 隐私性与行为可预测性         |

这些选择优先保障 “系统稳定性”，而非 “理论最优性”。


## 总结
AI 辅助阅读系统的多语言支持，不是 “加个翻译层” 或 “选个最大的模型” 这么简单。

它的核心是：
- 将语言作为系统参数
- 为有限的本地资源做设计
- 让 AI 辅助对用户 “有用” 且 "敢用（省钱）"

Mindory 的思路是“先把工程基础做对” —— 通过解决这些“小问题”，AI 辅助阅读才能在多语言场景下，真正实用、可扩展、可信赖。